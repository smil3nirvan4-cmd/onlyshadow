"""
S.S.I. SHADOW ‚Äî GROAS-LIKE AI ADS SYSTEM
COMPLETE IMPLEMENTATION BASED ON PRODUCT ANALYSIS

Baseado na an√°lise detalhada do groas.ai:

CORE AGENTS (conforme documentado):
1. Search Intent Agents - NLP para entender contexto, urg√™ncia, objetivo (research/comparison/purchase)
2. Conversion Copy Agents - Treinados em $500B+ de profitable ad spend, 2-3x convers√£o m√©dia
3. Budgeting Agents - Bloqueia keywords irrelevantes, encontra tr√°fego mais barato, evita bids caros
4. Opportunity Discovery Agents - Identifica novos canais de receita, refina arquitetura do funil
5. Optimization Agents - Milhares de A/B tests simult√¢neos 24/7
6. Performance Maximizers - Shift budget para search terms de maior convers√£o
7. Waste Eliminators - Identifica e bloqueia tr√°fego low-quality antes de gastar budget
8. Creative Refreshers - Gera novas varia√ß√µes quando performance come√ßa a plat√¥
9. Budget Guardians - Nunca excede limites sem ROI positivo previsto

FEATURES DOCUMENTADAS:
- Dynamic Landing Pages: Uma p√°gina com varia√ß√µes din√¢micas por keyword
- Funnel Tab: Analisa dados real-time, sugere oportunidades de crescimento
- Quality Score Optimization: 247+ vari√°veis contextuais
- Message Match: Alinhamento perfeito ad ‚Üí landing page
- 24/7 Self-Optimization: Ajustes de bid a cada hora

PRICING REFERENCE: $99/month unlimited accounts/spend
"""

import os
import json
import hashlib
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple, Set, Union
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import numpy as np
from collections import defaultdict
import re
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('ssi_groas_system')

# =============================================================================
# ENUMS & TYPES
# =============================================================================

class SearchIntentCategory(Enum):
    """Categorias de intent conforme GROAS"""
    RESEARCH = "research"  # Usu√°rio pesquisando
    COMPARISON = "comparison"  # Comparando op√ß√µes
    PURCHASE = "purchase"  # Pronto para comprar
    NAVIGATION = "navigation"  # Buscando site espec√≠fico


class UrgencyLevel(Enum):
    """N√≠vel de urg√™ncia detectado"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    IMMEDIATE = "immediate"


class AgentAction(Enum):
    """A√ß√µes que agentes podem tomar"""
    ADD_KEYWORD = "add_keyword"
    REMOVE_KEYWORD = "remove_keyword"
    ADD_NEGATIVE = "add_negative"
    ADJUST_BID = "adjust_bid"
    PAUSE_AD = "pause_ad"
    CREATE_AD = "create_ad"
    UPDATE_LANDING_PAGE = "update_landing_page"
    REALLOCATE_BUDGET = "reallocate_budget"
    CREATE_EXPERIMENT = "create_experiment"
    CONCLUDE_EXPERIMENT = "conclude_experiment"


class FunnelStage(Enum):
    """Est√°gio no funil"""
    AWARENESS = "awareness"
    CONSIDERATION = "consideration"
    DECISION = "decision"
    ACTION = "action"


@dataclass
class SearchContext:
    """Contexto completo de uma busca (247+ vari√°veis simplificadas)"""
    query: str
    
    # Intent analysis
    intent_category: SearchIntentCategory = SearchIntentCategory.RESEARCH
    urgency_level: UrgencyLevel = UrgencyLevel.MEDIUM
    funnel_stage: FunnelStage = FunnelStage.CONSIDERATION
    
    # User context
    device_type: str = "desktop"  # desktop, mobile, tablet
    operating_system: str = ""
    browser: str = ""
    
    # Temporal
    hour_of_day: int = 12
    day_of_week: int = 1  # 1=Monday
    is_weekend: bool = False
    is_business_hours: bool = True
    
    # Geographic
    country: str = "BR"
    region: str = ""
    city: str = ""
    timezone: str = "America/Sao_Paulo"
    
    # Behavioral (do S.S.I. Shadow)
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    trust_score: float = 0.5
    ltv_score: float = 0.5
    intent_score: float = 0.5
    is_returning_user: bool = False
    previous_visits: int = 0
    
    # Auction context
    competition_level: str = "medium"  # low, medium, high
    estimated_cpc: float = 0
    quality_score_estimate: int = 7
    
    # Extracted entities
    product_mentioned: str = ""
    brand_mentioned: str = ""
    modifier_words: List[str] = field(default_factory=list)
    price_sensitivity: str = "medium"  # low, medium, high


@dataclass
class ConversionCopyOutput:
    """Output do Conversion Copy Agent"""
    headlines: List[Dict[str, Any]]  # [{text, score, type}]
    descriptions: List[Dict[str, Any]]
    
    # Best combinations
    best_headline: str = ""
    best_description: str = ""
    
    # Dynamic elements
    dynamic_keyword_insertion: str = ""
    countdown_text: str = ""
    
    # Predictions
    predicted_ctr: float = 0
    predicted_cvr: float = 0
    confidence: float = 0
    
    # Reasoning
    reasoning: str = ""


@dataclass
class BudgetAction:
    """A√ß√£o de budget recomendada"""
    action_type: str  # increase, decrease, maintain, pause
    entity_type: str  # campaign, ad_group, keyword
    entity_id: str
    current_value: float
    recommended_value: float
    reason: str
    expected_impact: str
    confidence: float


@dataclass 
class OpportunityDiscovery:
    """Oportunidade descoberta pelo agente"""
    opportunity_type: str  # new_keyword, new_audience, new_channel, funnel_improvement
    description: str
    potential_revenue: float
    implementation_effort: str  # low, medium, high
    priority_score: float
    recommended_action: str
    supporting_data: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ExperimentResult:
    """Resultado de experimento A/B"""
    experiment_id: str
    variant_a: Dict[str, Any]
    variant_b: Dict[str, Any]
    
    winner: str  # 'a', 'b', 'inconclusive'
    lift_percentage: float
    statistical_significance: float
    sample_size: int
    
    recommendation: str
    auto_applied: bool = False


# =============================================================================
# SEARCH INTENT ENGINE
# =============================================================================

class SearchIntentEngine:
    """
    Search Intent Understanding Engine.
    Usa NLP para interpretar contexto, urg√™ncia e objetivo de cada busca.
    
    Conforme GROAS: "Uses Natural Language Processing (NLP) and machine learning 
    to interpret the context, urgency, and objective of a search"
    """
    
    # Intent signals baseados em an√°lise do GROAS
    PURCHASE_SIGNALS = {
        'high': [
            'comprar', 'buy', 'pre√ßo', 'price', 'quanto custa', 'valor',
            'onde comprar', 'loja', 'store', 'shop', 'adicionar carrinho',
            'frete', 'entrega', 'parcelar', 'desconto', 'cupom', 'oferta'
        ],
        'medium': [
            'melhor pre√ßo', 'promo√ß√£o', 'black friday', 'outlet',
            'barato', 'cheap', 'em conta', 'economia'
        ]
    }
    
    COMPARISON_SIGNALS = {
        'high': [
            'vs', 'versus', 'comparar', 'compare', 'diferen√ßa entre',
            'qual melhor', 'which better', 'alternativa', 'alternative'
        ],
        'medium': [
            'review', 'avalia√ß√£o', 'opini√£o', 'pr√≥s e contras',
            'vale a pena', 'worth it', 'recomenda√ß√£o'
        ]
    }
    
    RESEARCH_SIGNALS = {
        'high': [
            'o que √©', 'what is', 'como funciona', 'how does',
            'por que', 'why', 'guia', 'guide', 'tutorial'
        ],
        'medium': [
            'tipos de', 'types of', 'benef√≠cios', 'benefits',
            'caracter√≠sticas', 'features', 'especifica√ß√µes'
        ]
    }
    
    URGENCY_SIGNALS = {
        'immediate': [
            'agora', 'now', 'hoje', 'today', 'urgente', 'urgent',
            'r√°pido', 'fast', 'express', 'imediato', 'j√°'
        ],
        'high': [
            'amanh√£', 'tomorrow', 'esta semana', 'this week',
            'pr√≥ximo', 'soon', 'precisando'
        ]
    }
    
    PRICE_SENSITIVITY_SIGNALS = {
        'high': [
            'barato', 'cheap', 'econ√¥mico', 'em conta', 'custo benef√≠cio',
            'or√ßamento', 'budget', 'acess√≠vel', 'affordable'
        ],
        'low': [
            'premium', 'luxury', 'melhor', 'best', 'top', 'profissional',
            'enterprise', 'alta qualidade', 'high quality'
        ]
    }
    
    def __init__(self):
        self.context_weights = {
            'query_signals': 0.40,
            'device_context': 0.10,
            'temporal_context': 0.10,
            'user_history': 0.20,
            'behavioral_signals': 0.20
        }
    
    def analyze(self, query: str, context: Dict[str, Any] = None) -> SearchContext:
        """
        Analisa query e retorna contexto completo.
        Conforme GROAS: analisa 247+ vari√°veis contextuais.
        """
        ctx = context or {}
        query_lower = query.lower()
        
        # 1. Detect intent category
        intent_category = self._detect_intent_category(query_lower)
        
        # 2. Detect urgency
        urgency = self._detect_urgency(query_lower, ctx)
        
        # 3. Detect funnel stage
        funnel_stage = self._detect_funnel_stage(intent_category, urgency)
        
        # 4. Extract entities
        entities = self._extract_entities(query_lower)
        
        # 5. Detect price sensitivity
        price_sensitivity = self._detect_price_sensitivity(query_lower)
        
        # 6. Calculate conversion probability
        conversion_prob = self._calculate_conversion_probability(
            intent_category, urgency, ctx
        )
        
        return SearchContext(
            query=query,
            intent_category=intent_category,
            urgency_level=urgency,
            funnel_stage=funnel_stage,
            device_type=ctx.get('device', 'desktop'),
            hour_of_day=ctx.get('hour', datetime.now().hour),
            day_of_week=ctx.get('day_of_week', datetime.now().weekday() + 1),
            is_weekend=ctx.get('day_of_week', datetime.now().weekday()) >= 5,
            is_business_hours=9 <= ctx.get('hour', 12) <= 18,
            country=ctx.get('country', 'BR'),
            user_id=ctx.get('user_id'),
            trust_score=ctx.get('trust_score', 0.5),
            ltv_score=ctx.get('ltv_score', 0.5),
            intent_score=conversion_prob,
            is_returning_user=ctx.get('is_returning', False),
            product_mentioned=entities.get('product', ''),
            brand_mentioned=entities.get('brand', ''),
            modifier_words=entities.get('modifiers', []),
            price_sensitivity=price_sensitivity
        )
    
    def _detect_intent_category(self, query: str) -> SearchIntentCategory:
        """Detecta categoria de intent"""
        scores = {
            SearchIntentCategory.PURCHASE: 0,
            SearchIntentCategory.COMPARISON: 0,
            SearchIntentCategory.RESEARCH: 0,
            SearchIntentCategory.NAVIGATION: 0
        }
        
        # Check purchase signals
        for signal in self.PURCHASE_SIGNALS['high']:
            if signal in query:
                scores[SearchIntentCategory.PURCHASE] += 0.3
        for signal in self.PURCHASE_SIGNALS['medium']:
            if signal in query:
                scores[SearchIntentCategory.PURCHASE] += 0.15
        
        # Check comparison signals
        for signal in self.COMPARISON_SIGNALS['high']:
            if signal in query:
                scores[SearchIntentCategory.COMPARISON] += 0.3
        for signal in self.COMPARISON_SIGNALS['medium']:
            if signal in query:
                scores[SearchIntentCategory.COMPARISON] += 0.15
        
        # Check research signals
        for signal in self.RESEARCH_SIGNALS['high']:
            if signal in query:
                scores[SearchIntentCategory.RESEARCH] += 0.3
        for signal in self.RESEARCH_SIGNALS['medium']:
            if signal in query:
                scores[SearchIntentCategory.RESEARCH] += 0.15
        
        # Default boost for purchase (ads context)
        scores[SearchIntentCategory.PURCHASE] += 0.1
        
        return max(scores, key=scores.get)
    
    def _detect_urgency(self, query: str, ctx: Dict) -> UrgencyLevel:
        """Detecta n√≠vel de urg√™ncia"""
        for signal in self.URGENCY_SIGNALS['immediate']:
            if signal in query:
                return UrgencyLevel.IMMEDIATE
        
        for signal in self.URGENCY_SIGNALS['high']:
            if signal in query:
                return UrgencyLevel.HIGH
        
        # Context-based urgency
        if ctx.get('is_returning', False) and ctx.get('cart_value', 0) > 0:
            return UrgencyLevel.HIGH
        
        return UrgencyLevel.MEDIUM
    
    def _detect_funnel_stage(
        self,
        intent: SearchIntentCategory,
        urgency: UrgencyLevel
    ) -> FunnelStage:
        """Mapeia intent + urgency para est√°gio do funil"""
        if intent == SearchIntentCategory.PURCHASE:
            if urgency in [UrgencyLevel.IMMEDIATE, UrgencyLevel.HIGH]:
                return FunnelStage.ACTION
            return FunnelStage.DECISION
        elif intent == SearchIntentCategory.COMPARISON:
            return FunnelStage.DECISION
        elif intent == SearchIntentCategory.RESEARCH:
            return FunnelStage.CONSIDERATION
        else:
            return FunnelStage.AWARENESS
    
    def _extract_entities(self, query: str) -> Dict[str, Any]:
        """Extrai entidades da query"""
        entities = {
            'product': '',
            'brand': '',
            'modifiers': []
        }
        
        # Modifiers
        modifiers = ['melhor', 'top', 'barato', 'premium', 'profissional', 'para iniciantes']
        for mod in modifiers:
            if mod in query:
                entities['modifiers'].append(mod)
        
        return entities
    
    def _detect_price_sensitivity(self, query: str) -> str:
        """Detecta sensibilidade a pre√ßo"""
        for signal in self.PRICE_SENSITIVITY_SIGNALS['high']:
            if signal in query:
                return 'high'
        
        for signal in self.PRICE_SENSITIVITY_SIGNALS['low']:
            if signal in query:
                return 'low'
        
        return 'medium'
    
    def _calculate_conversion_probability(
        self,
        intent: SearchIntentCategory,
        urgency: UrgencyLevel,
        ctx: Dict
    ) -> float:
        """Calcula probabilidade de convers√£o"""
        base_prob = {
            SearchIntentCategory.PURCHASE: 0.15,
            SearchIntentCategory.COMPARISON: 0.08,
            SearchIntentCategory.RESEARCH: 0.02,
            SearchIntentCategory.NAVIGATION: 0.05
        }[intent]
        
        # Urgency multiplier
        urgency_mult = {
            UrgencyLevel.IMMEDIATE: 1.5,
            UrgencyLevel.HIGH: 1.3,
            UrgencyLevel.MEDIUM: 1.0,
            UrgencyLevel.LOW: 0.8
        }[urgency]
        
        prob = base_prob * urgency_mult
        
        # Context adjustments
        if ctx.get('is_returning', False):
            prob *= 1.2
        
        if ctx.get('trust_score', 0.5) > 0.7:
            prob *= 1.15
        
        return min(1.0, prob)


# =============================================================================
# CONVERSION COPY AGENT
# =============================================================================

class ConversionCopyAgent:
    """
    Conversion Copy Agent.
    Conforme GROAS: "Trained on $500B+ in Profitable Search Ad Spend to generate 
    messaging that converts at 2-3x industry average"
    """
    
    # Templates baseados em an√°lise de alta performance
    HEADLINE_PATTERNS = {
        'purchase': {
            'urgency': [
                "{keyword} - {discount}% OFF S√≥ Hoje",
                "‚ö° {keyword} em Promo√ß√£o | Aproveite",
                "üî• √öltimas {count} Unidades de {keyword}",
                "{keyword} | Frete Gr√°tis + {discount}% OFF"
            ],
            'value': [
                "{keyword} - Melhor Pre√ßo Garantido",
                "Compre {keyword} | At√© {discount}% OFF",
                "{keyword} Original | Parcele em 12x",
                "{keyword} com Garantia | Entrega Expressa"
            ],
            'trust': [
                "{keyword} | {rating}‚òÖ ({reviews}+ Avalia√ß√µes)",
                "{keyword} - {sold}+ Vendidos",
                "{keyword} Oficial | Garantia {warranty}",
                "Site Seguro | {keyword} Original"
            ]
        },
        'comparison': {
            'authority': [
                "Melhor {keyword} de {year} | Comparativo",
                "Top {count} {keyword} | An√°lise Completa",
                "{keyword}: Qual Escolher? | Guia {year}",
                "Compare {keyword} | Pr√≥s e Contras"
            ]
        },
        'research': {
            'educational': [
                "O Que √© {keyword}? | Guia Completo",
                "{keyword}: Tudo Que Voc√™ Precisa Saber",
                "Como Escolher {keyword} | Dicas de Especialista",
                "Guia {keyword} {year} | Aprenda Agora"
            ]
        }
    }
    
    DESCRIPTION_PATTERNS = {
        'purchase': [
            "‚úì {keyword} com os melhores pre√ßos do mercado. {discount}% de desconto + frete gr√°tis acima de R${min_order}. Compre agora!",
            "Encontre {keyword} de qualidade. Entrega em at√© {days} dias √∫teis. Parcele em at√© 12x sem juros. Satisfa√ß√£o garantida!",
            "{reviews}+ clientes satisfeitos. {keyword} original com {warranty} de garantia. Compra 100% segura. Aproveite!",
            "Ofertas exclusivas em {keyword}. Estoque limitado! {sold}+ j√° vendidos. N√£o perca essa oportunidade."
        ],
        'comparison': [
            "Compare os melhores {keyword} do mercado. An√°lises detalhadas de especialistas. Encontre o ideal para voc√™.",
            "Guia completo de {keyword}: pr√≥s, contras e custo-benef√≠cio. Avalia√ß√µes reais de quem j√° comprou.",
            "Descubra qual {keyword} oferece o melhor valor. Comparativo atualizado {year} com {count}+ op√ß√µes analisadas."
        ],
        'research': [
            "Aprenda tudo sobre {keyword}. Guia completo e atualizado com dicas de especialistas. 100% gratuito.",
            "Descubra como {keyword} pode ajudar voc√™. Tutorial passo a passo para iniciantes. Comece agora!",
            "Tire todas suas d√∫vidas sobre {keyword}. Conte√∫do educativo de qualidade. Atualizado {year}."
        ]
    }
    
    # Power words que aumentam CTR (baseado em dados reais)
    POWER_WORDS = {
        'urgency': ['agora', 'hoje', '√∫ltima chance', 'limitado', 'acaba em'],
        'exclusivity': ['exclusivo', 'vip', 'premium', 'especial', '√∫nico'],
        'trust': ['garantido', 'certificado', 'oficial', 'original', 'seguro'],
        'value': ['gr√°tis', 'desconto', 'economia', 'promo√ß√£o', 'oferta'],
        'social_proof': ['mais vendido', 'recomendado', 'favorito', 'popular']
    }
    
    def __init__(self):
        self.default_values = {
            'discount': '20',
            'count': '10',
            'min_order': '99',
            'days': '3',
            'warranty': '1 ano',
            'rating': '4.8',
            'reviews': '10.000',
            'sold': '50.000',
            'year': str(datetime.now().year)
        }
    
    def generate(
        self,
        keyword: str,
        search_context: SearchContext,
        brand_context: Dict[str, Any] = None
    ) -> ConversionCopyOutput:
        """
        Gera copy otimizado para convers√£o.
        Alinha mensagem com intent e urg√™ncia detectados.
        """
        brand = brand_context or {}
        
        # Select patterns based on intent
        intent_key = {
            SearchIntentCategory.PURCHASE: 'purchase',
            SearchIntentCategory.COMPARISON: 'comparison',
            SearchIntentCategory.RESEARCH: 'research',
            SearchIntentCategory.NAVIGATION: 'purchase'
        }[search_context.intent_category]
        
        # Generate headlines
        headlines = self._generate_headlines(
            keyword, intent_key, search_context, brand
        )
        
        # Generate descriptions
        descriptions = self._generate_descriptions(
            keyword, intent_key, search_context, brand
        )
        
        # Select best combinations
        best_headline = headlines[0] if headlines else {'text': '', 'score': 0}
        best_description = descriptions[0] if descriptions else {'text': '', 'score': 0}
        
        # Predict performance
        predicted_ctr = self._predict_ctr(best_headline, search_context)
        predicted_cvr = self._predict_cvr(best_headline, best_description, search_context)
        
        # Generate reasoning
        reasoning = self._generate_reasoning(search_context, best_headline)
        
        return ConversionCopyOutput(
            headlines=headlines,
            descriptions=descriptions,
            best_headline=best_headline['text'],
            best_description=best_description['text'],
            dynamic_keyword_insertion=f"{{KeyWord:{keyword.title()}}}",
            countdown_text=self._generate_countdown() if search_context.urgency_level == UrgencyLevel.IMMEDIATE else "",
            predicted_ctr=predicted_ctr,
            predicted_cvr=predicted_cvr,
            confidence=0.85,
            reasoning=reasoning
        )
    
    def _generate_headlines(
        self,
        keyword: str,
        intent_key: str,
        context: SearchContext,
        brand: Dict
    ) -> List[Dict[str, Any]]:
        """Gera headlines rankeados por score"""
        headlines = []
        
        patterns = self.HEADLINE_PATTERNS.get(intent_key, {})
        
        # Select sub-patterns based on context
        if context.urgency_level in [UrgencyLevel.IMMEDIATE, UrgencyLevel.HIGH]:
            sub_patterns = patterns.get('urgency', patterns.get('authority', []))
        elif context.price_sensitivity == 'high':
            sub_patterns = patterns.get('value', patterns.get('authority', []))
        else:
            sub_patterns = patterns.get('trust', patterns.get('authority', []))
        
        # Add fallback patterns
        for pattern_type in patterns.values():
            sub_patterns.extend(pattern_type[:2])
        
        # Generate and score
        for pattern in sub_patterns[:10]:
            text = self._fill_template(pattern, keyword, brand)
            
            # Truncate to 30 chars
            if len(text) > 30:
                text = text[:27] + "..."
            
            score = self._score_headline(text, keyword, context)
            
            headlines.append({
                'text': text,
                'score': score,
                'type': 'generated'
            })
        
        # Sort by score
        headlines.sort(key=lambda x: x['score'], reverse=True)
        
        return headlines[:15]  # Max 15 headlines for RSA
    
    def _generate_descriptions(
        self,
        keyword: str,
        intent_key: str,
        context: SearchContext,
        brand: Dict
    ) -> List[Dict[str, Any]]:
        """Gera descriptions rankeadas"""
        descriptions = []
        
        patterns = self.DESCRIPTION_PATTERNS.get(intent_key, self.DESCRIPTION_PATTERNS['purchase'])
        
        for pattern in patterns:
            text = self._fill_template(pattern, keyword, brand)
            
            # Truncate to 90 chars
            if len(text) > 90:
                text = text[:87] + "..."
            
            score = self._score_description(text, keyword, context)
            
            descriptions.append({
                'text': text,
                'score': score
            })
        
        descriptions.sort(key=lambda x: x['score'], reverse=True)
        
        return descriptions[:4]  # Max 4 descriptions for RSA
    
    def _fill_template(self, template: str, keyword: str, brand: Dict) -> str:
        """Preenche template com valores"""
        values = {**self.default_values, **brand}
        values['keyword'] = keyword.title()
        
        result = template
        for key, value in values.items():
            result = result.replace(f'{{{key}}}', str(value))
        
        return result
    
    def _score_headline(self, text: str, keyword: str, context: SearchContext) -> float:
        """Pontua headline"""
        score = 0.5
        text_lower = text.lower()
        
        # Keyword presence
        if keyword.lower() in text_lower:
            score += 0.2
        
        # Power words
        for category, words in self.POWER_WORDS.items():
            for word in words:
                if word in text_lower:
                    score += 0.03
        
        # Length optimization
        length = len(text)
        if 20 <= length <= 30:
            score += 0.1
        
        # Numbers boost CTR
        if any(c.isdigit() for c in text):
            score += 0.05
        
        # Emoji (for some formats)
        if any(ord(c) > 127 for c in text):
            score += 0.02
        
        return min(1.0, score)
    
    def _score_description(self, text: str, keyword: str, context: SearchContext) -> float:
        """Pontua description"""
        score = 0.5
        text_lower = text.lower()
        
        if keyword.lower() in text_lower:
            score += 0.15
        
        # Check marks and bullets
        if '‚úì' in text or '‚Ä¢' in text:
            score += 0.05
        
        # CTA presence
        cta_words = ['compre', 'aproveite', 'descubra', 'saiba', 'clique']
        if any(cta in text_lower for cta in cta_words):
            score += 0.1
        
        return min(1.0, score)
    
    def _predict_ctr(self, headline: Dict, context: SearchContext) -> float:
        """Prediz CTR baseado em headline + context"""
        base_ctr = 0.035  # 3.5% baseline
        
        # Headline score impact
        base_ctr *= (1 + headline.get('score', 0.5))
        
        # Intent impact
        intent_mult = {
            SearchIntentCategory.PURCHASE: 1.3,
            SearchIntentCategory.COMPARISON: 1.1,
            SearchIntentCategory.RESEARCH: 0.8,
            SearchIntentCategory.NAVIGATION: 1.0
        }[context.intent_category]
        
        base_ctr *= intent_mult
        
        # Device impact
        if context.device_type == 'mobile':
            base_ctr *= 0.9
        
        return min(0.15, base_ctr)  # Cap at 15%
    
    def _predict_cvr(self, headline: Dict, description: Dict, context: SearchContext) -> float:
        """Prediz CVR"""
        base_cvr = 0.025  # 2.5% baseline
        
        # Intent impact
        intent_mult = {
            SearchIntentCategory.PURCHASE: 2.0,
            SearchIntentCategory.COMPARISON: 1.2,
            SearchIntentCategory.RESEARCH: 0.5,
            SearchIntentCategory.NAVIGATION: 1.0
        }[context.intent_category]
        
        base_cvr *= intent_mult
        
        # Trust score impact
        base_cvr *= (0.5 + context.trust_score)
        
        return min(0.20, base_cvr)  # Cap at 20%
    
    def _generate_countdown(self) -> str:
        """Gera texto de countdown"""
        hours = random.randint(2, 24)
        return f"‚è∞ Oferta expira em {hours}h"
    
    def _generate_reasoning(self, context: SearchContext, headline: Dict) -> str:
        """Gera explica√ß√£o do racioc√≠nio"""
        return f"""
Intent detectado: {context.intent_category.value} (urg√™ncia: {context.urgency_level.value})
Est√°gio do funil: {context.funnel_stage.value}
Sensibilidade a pre√ßo: {context.price_sensitivity}
Headline score: {headline.get('score', 0):.2f}
Alinhamento: Copy otimizado para {context.intent_category.value} com foco em {'urg√™ncia' if context.urgency_level in [UrgencyLevel.IMMEDIATE, UrgencyLevel.HIGH] else 'valor/confian√ßa'}
        """.strip()


# =============================================================================
# BUDGETING AGENT
# =============================================================================

class BudgetingAgent:
    """
    Budgeting Agent.
    Conforme GROAS: "Automatically blocks irrelevant keywords, avoids costly bids 
    and uncovers cheaper high-quality traffic"
    """
    
    def __init__(self):
        self.min_conversions_for_decision = 3
        self.max_cpa_multiplier = 2.0  # Pause se CPA > 2x target
        self.min_roas = 1.0
    
    def analyze_and_recommend(
        self,
        keywords: List[Dict],
        search_terms: List[Dict],
        budget: float,
        target_cpa: float,
        target_roas: float
    ) -> Dict[str, Any]:
        """
        Analisa keywords/search terms e recomenda a√ß√µes de budget.
        """
        actions = []
        
        # 1. Identify waste (keywords to pause/negative)
        waste_keywords = self._identify_waste(keywords, target_cpa, target_roas)
        for kw in waste_keywords:
            actions.append(BudgetAction(
                action_type='pause' if kw['type'] == 'keyword' else 'add_negative',
                entity_type=kw['type'],
                entity_id=kw['id'],
                current_value=kw['cost'],
                recommended_value=0,
                reason=kw['reason'],
                expected_impact=f"Economia de R${kw['cost']:.2f}/m√™s",
                confidence=kw['confidence']
            ))
        
        # 2. Identify opportunities (keywords to increase bid)
        opportunities = self._identify_opportunities(keywords, target_roas)
        for opp in opportunities:
            actions.append(BudgetAction(
                action_type='increase',
                entity_type='keyword',
                entity_id=opp['id'],
                current_value=opp['current_bid'],
                recommended_value=opp['recommended_bid'],
                reason=opp['reason'],
                expected_impact=f"Aumento estimado de {opp['expected_lift']:.0%} em convers√µes",
                confidence=opp['confidence']
            ))
        
        # 3. Find cheaper traffic
        cheaper_traffic = self._find_cheaper_traffic(search_terms, target_cpa)
        
        # 4. Calculate savings and reallocation
        total_waste = sum(a.current_value for a in actions if a.action_type in ['pause', 'add_negative'])
        
        return {
            'actions': [a.__dict__ for a in actions],
            'total_waste_identified': total_waste,
            'cheaper_traffic_opportunities': cheaper_traffic,
            'budget_efficiency_score': self._calculate_efficiency_score(keywords),
            'recommendations_summary': self._generate_summary(actions, total_waste)
        }
    
    def _identify_waste(
        self,
        keywords: List[Dict],
        target_cpa: float,
        target_roas: float
    ) -> List[Dict]:
        """Identifica keywords que est√£o desperdi√ßando budget"""
        waste = []
        
        for kw in keywords:
            cost = kw.get('cost', 0)
            conversions = kw.get('conversions', 0)
            revenue = kw.get('revenue', 0)
            impressions = kw.get('impressions', 0)
            clicks = kw.get('clicks', 0)
            
            # Skip low data
            if cost < 10:
                continue
            
            # Calculate metrics
            cpa = cost / conversions if conversions > 0 else float('inf')
            roas = revenue / cost if cost > 0 else 0
            ctr = clicks / impressions if impressions > 0 else 0
            
            # Check for waste
            if conversions == 0 and cost > target_cpa * 2:
                waste.append({
                    'id': kw.get('id', ''),
                    'keyword': kw.get('keyword', ''),
                    'type': 'keyword',
                    'cost': cost,
                    'reason': f'Zero convers√µes com R${cost:.2f} gasto (>2x target CPA)',
                    'confidence': 0.9
                })
            elif cpa > target_cpa * self.max_cpa_multiplier and conversions >= self.min_conversions_for_decision:
                waste.append({
                    'id': kw.get('id', ''),
                    'keyword': kw.get('keyword', ''),
                    'type': 'keyword',
                    'cost': cost,
                    'reason': f'CPA de R${cpa:.2f} > {self.max_cpa_multiplier}x target',
                    'confidence': 0.85
                })
            elif roas < self.min_roas and conversions >= self.min_conversions_for_decision:
                waste.append({
                    'id': kw.get('id', ''),
                    'keyword': kw.get('keyword', ''),
                    'type': 'keyword',
                    'cost': cost,
                    'reason': f'ROAS de {roas:.2f}x < m√≠nimo de {self.min_roas}x',
                    'confidence': 0.8
                })
            elif ctr < 0.005 and impressions > 1000:
                waste.append({
                    'id': kw.get('id', ''),
                    'keyword': kw.get('keyword', ''),
                    'type': 'keyword',
                    'cost': cost,
                    'reason': f'CTR muito baixo ({ctr:.2%}) indica baixa relev√¢ncia',
                    'confidence': 0.75
                })
        
        return waste
    
    def _identify_opportunities(
        self,
        keywords: List[Dict],
        target_roas: float
    ) -> List[Dict]:
        """Identifica keywords com potencial de escala"""
        opportunities = []
        
        for kw in keywords:
            cost = kw.get('cost', 0)
            conversions = kw.get('conversions', 0)
            revenue = kw.get('revenue', 0)
            current_bid = kw.get('cpc', 0)
            impression_share = kw.get('impression_share', 1.0)
            
            if conversions < 3 or cost == 0:
                continue
            
            roas = revenue / cost
            
            # High ROAS with room to scale
            if roas > target_roas * 1.5 and impression_share < 0.8:
                recommended_bid = current_bid * 1.2  # 20% increase
                
                opportunities.append({
                    'id': kw.get('id', ''),
                    'keyword': kw.get('keyword', ''),
                    'current_bid': current_bid,
                    'recommended_bid': recommended_bid,
                    'reason': f'ROAS de {roas:.2f}x com impression share de {impression_share:.0%}',
                    'expected_lift': 0.15,
                    'confidence': 0.8
                })
        
        return opportunities
    
    def _find_cheaper_traffic(
        self,
        search_terms: List[Dict],
        target_cpa: float
    ) -> List[Dict]:
        """Encontra search terms com tr√°fego mais barato"""
        cheaper = []
        
        for term in search_terms:
            cost = term.get('cost', 0)
            conversions = term.get('conversions', 0)
            
            if conversions == 0 or cost == 0:
                continue
            
            cpa = cost / conversions
            
            if cpa < target_cpa * 0.5:  # CPA < 50% do target
                cheaper.append({
                    'term': term.get('term', ''),
                    'cpa': cpa,
                    'conversions': conversions,
                    'savings_vs_target': (target_cpa - cpa) * conversions,
                    'recommendation': 'Adicionar como keyword exata'
                })
        
        cheaper.sort(key=lambda x: x['savings_vs_target'], reverse=True)
        
        return cheaper[:10]
    
    def _calculate_efficiency_score(self, keywords: List[Dict]) -> float:
        """Calcula score de efici√™ncia do budget"""
        if not keywords:
            return 0.5
        
        total_cost = sum(kw.get('cost', 0) for kw in keywords)
        total_revenue = sum(kw.get('revenue', 0) for kw in keywords)
        
        if total_cost == 0:
            return 0.5
        
        roas = total_revenue / total_cost
        
        # Score 0-100 baseado em ROAS
        if roas >= 5:
            return 100
        elif roas >= 3:
            return 80
        elif roas >= 2:
            return 60
        elif roas >= 1:
            return 40
        else:
            return 20
    
    def _generate_summary(self, actions: List[BudgetAction], total_waste: float) -> str:
        """Gera sum√°rio das recomenda√ß√µes"""
        pause_count = sum(1 for a in actions if a.action_type == 'pause')
        negative_count = sum(1 for a in actions if a.action_type == 'add_negative')
        increase_count = sum(1 for a in actions if a.action_type == 'increase')
        
        return f"""
üìä Resumo de Otimiza√ß√£o de Budget:
- {pause_count} keywords para pausar
- {negative_count} negativos para adicionar  
- {increase_count} keywords para aumentar bid
- R${total_waste:.2f} de desperd√≠cio identificado
- Economia projetada: R${total_waste * 4:.2f}/m√™s
        """.strip()


# =============================================================================
# OPPORTUNITY DISCOVERY AGENT
# =============================================================================

class OpportunityDiscoveryAgent:
    """
    Opportunity Discovery Agent.
    Conforme GROAS: "Identifies new revenue channels and refines the overall 
    funnel architecture for continuous growth"
    """
    
    def __init__(self):
        pass
    
    def discover(
        self,
        current_keywords: List[Dict],
        search_terms: List[Dict],
        competitors: List[Dict] = None,
        industry_data: Dict = None
    ) -> List[OpportunityDiscovery]:
        """
        Descobre oportunidades de crescimento.
        """
        opportunities = []
        
        # 1. Find converting search terms not in keywords
        keyword_set = set(kw.get('keyword', '').lower() for kw in current_keywords)
        
        for term in search_terms:
            if term.get('conversions', 0) > 0:
                term_text = term.get('term', '').lower()
                if term_text not in keyword_set:
                    opportunities.append(OpportunityDiscovery(
                        opportunity_type='new_keyword',
                        description=f"Search term '{term_text}' converteu {term.get('conversions')}x mas n√£o √© keyword",
                        potential_revenue=term.get('revenue', 0) * 2,  # Estimate 2x with keyword
                        implementation_effort='low',
                        priority_score=0.9,
                        recommended_action=f"Adicionar '{term_text}' como keyword exata",
                        supporting_data={
                            'current_conversions': term.get('conversions'),
                            'current_revenue': term.get('revenue'),
                            'cpa': term.get('cost', 0) / term.get('conversions', 1)
                        }
                    ))
        
        # 2. Find keyword expansion opportunities
        expansion_opps = self._find_expansion_opportunities(current_keywords)
        opportunities.extend(expansion_opps)
        
        # 3. Find funnel improvements
        funnel_opps = self._find_funnel_improvements(current_keywords, search_terms)
        opportunities.extend(funnel_opps)
        
        # Sort by priority
        opportunities.sort(key=lambda x: x.priority_score, reverse=True)
        
        return opportunities[:20]
    
    def _find_expansion_opportunities(
        self,
        keywords: List[Dict]
    ) -> List[OpportunityDiscovery]:
        """Encontra oportunidades de expans√£o de keywords"""
        opportunities = []
        
        # Find high-performing keywords for expansion
        for kw in keywords:
            conversions = kw.get('conversions', 0)
            roas = kw.get('revenue', 0) / kw.get('cost', 1) if kw.get('cost', 0) > 0 else 0
            
            if conversions >= 5 and roas >= 3:
                keyword = kw.get('keyword', '')
                
                # Suggest variations
                variations = [
                    f"{keyword} pre√ßo",
                    f"{keyword} comprar",
                    f"melhor {keyword}",
                    f"{keyword} promo√ß√£o"
                ]
                
                opportunities.append(OpportunityDiscovery(
                    opportunity_type='new_keyword',
                    description=f"Expandir keyword de alta performance '{keyword}'",
                    potential_revenue=kw.get('revenue', 0) * 0.5,
                    implementation_effort='low',
                    priority_score=0.75,
                    recommended_action=f"Adicionar varia√ß√µes: {', '.join(variations[:3])}",
                    supporting_data={
                        'base_keyword': keyword,
                        'base_roas': roas,
                        'suggested_variations': variations
                    }
                ))
        
        return opportunities
    
    def _find_funnel_improvements(
        self,
        keywords: List[Dict],
        search_terms: List[Dict]
    ) -> List[OpportunityDiscovery]:
        """Encontra melhorias no funil"""
        opportunities = []
        
        # Check for high-traffic low-conversion terms
        for term in search_terms:
            clicks = term.get('clicks', 0)
            conversions = term.get('conversions', 0)
            
            if clicks > 100 and conversions == 0:
                opportunities.append(OpportunityDiscovery(
                    opportunity_type='funnel_improvement',
                    description=f"'{term.get('term', '')}' tem {clicks} clicks mas 0 convers√µes",
                    potential_revenue=clicks * 0.02 * 100,  # Estimate 2% CVR * R$100 AOV
                    implementation_effort='medium',
                    priority_score=0.7,
                    recommended_action="Criar landing page espec√≠fica ou adicionar como negativo",
                    supporting_data={
                        'clicks': clicks,
                        'bounce_estimate': 0.8
                    }
                ))
        
        return opportunities


# =============================================================================
# OPTIMIZATION AGENT (A/B TESTING)
# =============================================================================

class OptimizationAgent:
    """
    Optimization Agent.
    Conforme GROAS: "Functions like data scientists, running thousands of A/B tests 
    simultaneously and around the clock"
    """
    
    def __init__(self):
        self.min_sample_size = 100
        self.confidence_threshold = 0.95
    
    def create_experiment(
        self,
        experiment_type: str,  # 'ad_copy', 'landing_page', 'bid'
        control: Dict,
        variant: Dict,
        traffic_split: float = 0.5
    ) -> Dict:
        """Cria novo experimento"""
        experiment_id = hashlib.md5(f"{datetime.now().isoformat()}:{experiment_type}".encode()).hexdigest()[:12]
        
        return {
            'experiment_id': experiment_id,
            'type': experiment_type,
            'status': 'running',
            'control': control,
            'variant': variant,
            'traffic_split': traffic_split,
            'created_at': datetime.now().isoformat(),
            'metrics': {
                'control': {'visitors': 0, 'conversions': 0},
                'variant': {'visitors': 0, 'conversions': 0}
            }
        }
    
    def analyze_experiment(
        self,
        experiment: Dict
    ) -> ExperimentResult:
        """Analisa resultados do experimento"""
        metrics = experiment.get('metrics', {})
        
        control = metrics.get('control', {})
        variant = metrics.get('variant', {})
        
        control_visitors = control.get('visitors', 0)
        control_conversions = control.get('conversions', 0)
        variant_visitors = variant.get('visitors', 0)
        variant_conversions = variant.get('conversions', 0)
        
        # Check sample size
        if control_visitors < self.min_sample_size or variant_visitors < self.min_sample_size:
            return ExperimentResult(
                experiment_id=experiment.get('experiment_id', ''),
                variant_a=control,
                variant_b=variant,
                winner='inconclusive',
                lift_percentage=0,
                statistical_significance=0,
                sample_size=control_visitors + variant_visitors,
                recommendation='Continuar coletando dados',
                auto_applied=False
            )
        
        # Calculate conversion rates
        cr_control = control_conversions / control_visitors if control_visitors > 0 else 0
        cr_variant = variant_conversions / variant_visitors if variant_visitors > 0 else 0
        
        # Calculate lift
        lift = (cr_variant - cr_control) / cr_control if cr_control > 0 else 0
        
        # Statistical significance (z-test)
        significance = self._calculate_significance(
            control_conversions, control_visitors,
            variant_conversions, variant_visitors
        )
        
        # Determine winner
        if significance >= self.confidence_threshold:
            if lift > 0:
                winner = 'b'
                recommendation = f'Variante B venceu com {lift:.1%} de lift. Aplicar.'
            else:
                winner = 'a'
                recommendation = f'Controle A √© melhor. Descartar variante.'
        else:
            winner = 'inconclusive'
            recommendation = 'Diferen√ßa n√£o √© estatisticamente significativa.'
        
        return ExperimentResult(
            experiment_id=experiment.get('experiment_id', ''),
            variant_a=control,
            variant_b=variant,
            winner=winner,
            lift_percentage=lift * 100,
            statistical_significance=significance,
            sample_size=control_visitors + variant_visitors,
            recommendation=recommendation,
            auto_applied=winner == 'b' and significance >= 0.99
        )
    
    def _calculate_significance(
        self,
        c_conv: int, c_vis: int,
        v_conv: int, v_vis: int
    ) -> float:
        """Calcula signific√¢ncia estat√≠stica"""
        if c_vis == 0 or v_vis == 0:
            return 0
        
        p1 = c_conv / c_vis
        p2 = v_conv / v_vis
        
        p_pool = (c_conv + v_conv) / (c_vis + v_vis)
        se = np.sqrt(p_pool * (1 - p_pool) * (1/c_vis + 1/v_vis))
        
        if se == 0:
            return 0
        
        z = abs(p2 - p1) / se
        
        # Convert z-score to confidence
        # Simplified approximation
        confidence = min(0.999, 0.5 + 0.5 * np.tanh(z * 0.5))
        
        return confidence


# =============================================================================
# FUNNEL TAB (DASHBOARD)
# =============================================================================

class FunnelTab:
    """
    Funnel Tab.
    Conforme GROAS: "Analyzes real-time data to optimize keywords, ad copy, and 
    landing pages... uncovering growth opportunities"
    """
    
    def __init__(self):
        self.intent_engine = SearchIntentEngine()
        self.copy_agent = ConversionCopyAgent()
        self.budget_agent = BudgetingAgent()
        self.opportunity_agent = OpportunityDiscoveryAgent()
        self.optimization_agent = OptimizationAgent()
    
    def analyze_funnel(
        self,
        campaigns: List[Dict],
        keywords: List[Dict],
        search_terms: List[Dict],
        ads: List[Dict],
        target_cpa: float,
        target_roas: float
    ) -> Dict[str, Any]:
        """
        An√°lise completa do funil.
        Retorna insights e a√ß√µes recomendadas.
        """
        # 1. Budget analysis
        budget_analysis = self.budget_agent.analyze_and_recommend(
            keywords, search_terms,
            budget=sum(c.get('daily_budget', 0) for c in campaigns),
            target_cpa=target_cpa,
            target_roas=target_roas
        )
        
        # 2. Opportunity discovery
        opportunities = self.opportunity_agent.discover(
            keywords, search_terms
        )
        
        # 3. Calculate funnel metrics
        funnel_metrics = self._calculate_funnel_metrics(campaigns, keywords)
        
        # 4. Identify top actions
        top_actions = self._prioritize_actions(
            budget_analysis.get('actions', []),
            opportunities
        )
        
        # 5. Generate insights
        insights = self._generate_insights(funnel_metrics, budget_analysis, opportunities)
        
        return {
            'funnel_metrics': funnel_metrics,
            'budget_analysis': budget_analysis,
            'opportunities': [o.__dict__ for o in opportunities],
            'top_actions': top_actions,
            'insights': insights,
            'health_score': self._calculate_health_score(funnel_metrics, budget_analysis)
        }
    
    def _calculate_funnel_metrics(
        self,
        campaigns: List[Dict],
        keywords: List[Dict]
    ) -> Dict[str, Any]:
        """Calcula m√©tricas do funil"""
        total_impressions = sum(c.get('impressions', 0) for c in campaigns)
        total_clicks = sum(c.get('clicks', 0) for c in campaigns)
        total_conversions = sum(c.get('conversions', 0) for c in campaigns)
        total_cost = sum(c.get('cost', 0) for c in campaigns)
        total_revenue = sum(c.get('revenue', 0) for c in campaigns)
        
        return {
            'impressions': total_impressions,
            'clicks': total_clicks,
            'conversions': total_conversions,
            'cost': total_cost,
            'revenue': total_revenue,
            'ctr': total_clicks / total_impressions if total_impressions > 0 else 0,
            'cvr': total_conversions / total_clicks if total_clicks > 0 else 0,
            'cpc': total_cost / total_clicks if total_clicks > 0 else 0,
            'cpa': total_cost / total_conversions if total_conversions > 0 else 0,
            'roas': total_revenue / total_cost if total_cost > 0 else 0,
            'active_keywords': len([k for k in keywords if k.get('status') == 'ENABLED']),
            'converting_keywords': len([k for k in keywords if k.get('conversions', 0) > 0])
        }
    
    def _prioritize_actions(
        self,
        budget_actions: List[Dict],
        opportunities: List[OpportunityDiscovery]
    ) -> List[Dict]:
        """Prioriza a√ß√µes por impacto"""
        all_actions = []
        
        # Add budget actions
        for action in budget_actions[:5]:
            all_actions.append({
                'type': 'budget',
                'action': action,
                'priority': action.get('confidence', 0.5)
            })
        
        # Add opportunity actions
        for opp in opportunities[:5]:
            all_actions.append({
                'type': 'opportunity',
                'action': opp.__dict__,
                'priority': opp.priority_score
            })
        
        # Sort by priority
        all_actions.sort(key=lambda x: x['priority'], reverse=True)
        
        return all_actions[:10]
    
    def _generate_insights(
        self,
        metrics: Dict,
        budget_analysis: Dict,
        opportunities: List
    ) -> List[str]:
        """Gera insights acion√°veis"""
        insights = []
        
        # ROAS insight
        roas = metrics.get('roas', 0)
        if roas < 1:
            insights.append(f"‚ö†Ô∏è ROAS de {roas:.2f}x est√° abaixo do break-even. Revise keywords e bids urgentemente.")
        elif roas > 5:
            insights.append(f"üöÄ ROAS excelente de {roas:.2f}x. Considere aumentar budget para escalar.")
        
        # Waste insight
        waste = budget_analysis.get('total_waste_identified', 0)
        if waste > 0:
            insights.append(f"üí∞ R${waste:.2f} identificados como desperd√≠cio. Aplique as a√ß√µes recomendadas.")
        
        # CVR insight
        cvr = metrics.get('cvr', 0)
        if cvr < 0.01:
            insights.append(f"üìâ CVR de {cvr:.2%} est√° baixo. Revise landing pages e message match.")
        
        # Opportunity insight
        if opportunities:
            top_opp = opportunities[0]
            insights.append(f"üí° Oportunidade: {top_opp.description}")
        
        return insights
    
    def _calculate_health_score(
        self,
        metrics: Dict,
        budget_analysis: Dict
    ) -> int:
        """Calcula score de sa√∫de do funnel (0-100)"""
        score = 50  # Base
        
        # ROAS impact
        roas = metrics.get('roas', 0)
        if roas >= 5:
            score += 20
        elif roas >= 3:
            score += 15
        elif roas >= 2:
            score += 10
        elif roas >= 1:
            score += 5
        else:
            score -= 10
        
        # CVR impact
        cvr = metrics.get('cvr', 0)
        if cvr >= 0.05:
            score += 15
        elif cvr >= 0.02:
            score += 10
        elif cvr >= 0.01:
            score += 5
        
        # Efficiency impact
        efficiency = budget_analysis.get('budget_efficiency_score', 50)
        score += (efficiency - 50) / 5
        
        return max(0, min(100, int(score)))


# =============================================================================
# MAIN GROAS ENGINE
# =============================================================================

class GROASEngine:
    """
    Main GROAS-like Engine.
    Orquestra todos os agentes para otimiza√ß√£o 24/7.
    """
    
    def __init__(self):
        self.intent_engine = SearchIntentEngine()
        self.copy_agent = ConversionCopyAgent()
        self.budget_agent = BudgetingAgent()
        self.opportunity_agent = OpportunityDiscoveryAgent()
        self.optimization_agent = OptimizationAgent()
        self.funnel_tab = FunnelTab()
        
        self.execution_log = []
    
    async def run_full_optimization(
        self,
        account_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Executa ciclo completo de otimiza√ß√£o.
        Conforme GROAS: "24/7 Self-Optimization"
        """
        results = {
            'timestamp': datetime.now().isoformat(),
            'account_id': account_data.get('account_id', ''),
            'optimizations': [],
            'summary': {}
        }
        
        campaigns = account_data.get('campaigns', [])
        keywords = account_data.get('keywords', [])
        search_terms = account_data.get('search_terms', [])
        ads = account_data.get('ads', [])
        target_cpa = account_data.get('target_cpa', 50)
        target_roas = account_data.get('target_roas', 3.0)
        
        # 1. Full funnel analysis
        funnel_analysis = self.funnel_tab.analyze_funnel(
            campaigns, keywords, search_terms, ads,
            target_cpa, target_roas
        )
        results['funnel_analysis'] = funnel_analysis
        
        # 2. Generate optimized copy for top keywords
        copy_optimizations = []
        top_keywords = sorted(keywords, key=lambda x: x.get('conversions', 0), reverse=True)[:10]
        
        for kw in top_keywords:
            keyword = kw.get('keyword', '')
            context = self.intent_engine.analyze(keyword)
            copy = self.copy_agent.generate(keyword, context)
            
            copy_optimizations.append({
                'keyword': keyword,
                'intent': context.intent_category.value,
                'best_headline': copy.best_headline,
                'predicted_ctr': copy.predicted_ctr
            })
        
        results['copy_optimizations'] = copy_optimizations
        
        # 3. Apply budget recommendations
        # (In production, would integrate with Google Ads API)
        
        # 4. Log execution
        self.execution_log.append({
            'timestamp': results['timestamp'],
            'health_score': funnel_analysis.get('health_score', 0),
            'actions_recommended': len(funnel_analysis.get('top_actions', []))
        })
        
        # 5. Generate summary
        results['summary'] = {
            'health_score': funnel_analysis.get('health_score', 0),
            'total_opportunities': len(funnel_analysis.get('opportunities', [])),
            'waste_identified': funnel_analysis.get('budget_analysis', {}).get('total_waste_identified', 0),
            'top_insight': funnel_analysis.get('insights', [''])[0] if funnel_analysis.get('insights') else '',
            'copy_improvements': len(copy_optimizations)
        }
        
        return results
    
    def analyze_search_query(
        self,
        query: str,
        context: Dict = None
    ) -> Dict[str, Any]:
        """
        Analisa uma query de busca e retorna recommendations.
        Similar ao que GROAS faz em tempo real para cada busca.
        """
        # Analyze intent
        search_context = self.intent_engine.analyze(query, context)
        
        # Generate optimal copy
        copy = self.copy_agent.generate(query, search_context)
        
        return {
            'query': query,
            'intent': {
                'category': search_context.intent_category.value,
                'urgency': search_context.urgency_level.value,
                'funnel_stage': search_context.funnel_stage.value,
                'conversion_probability': search_context.intent_score
            },
            'recommended_ad': {
                'headline': copy.best_headline,
                'description': copy.best_description,
                'predicted_ctr': copy.predicted_ctr,
                'predicted_cvr': copy.predicted_cvr
            },
            'bid_recommendation': {
                'multiplier': self._calculate_bid_multiplier(search_context),
                'reason': f"Intent: {search_context.intent_category.value}, Urgency: {search_context.urgency_level.value}"
            }
        }
    
    def _calculate_bid_multiplier(self, context: SearchContext) -> float:
        """Calcula multiplicador de bid baseado no contexto"""
        base = 1.0
        
        # Intent adjustment
        intent_mult = {
            SearchIntentCategory.PURCHASE: 1.3,
            SearchIntentCategory.COMPARISON: 1.1,
            SearchIntentCategory.RESEARCH: 0.7,
            SearchIntentCategory.NAVIGATION: 1.0
        }[context.intent_category]
        
        # Urgency adjustment
        urgency_mult = {
            UrgencyLevel.IMMEDIATE: 1.2,
            UrgencyLevel.HIGH: 1.1,
            UrgencyLevel.MEDIUM: 1.0,
            UrgencyLevel.LOW: 0.9
        }[context.urgency_level]
        
        # Trust score adjustment
        trust_mult = 0.9 + (context.trust_score * 0.2)
        
        return base * intent_mult * urgency_mult * trust_mult


# =============================================================================
# EXPORTS
# =============================================================================

__all__ = [
    # Enums
    'SearchIntentCategory',
    'UrgencyLevel',
    'AgentAction',
    'FunnelStage',
    
    # Data classes
    'SearchContext',
    'ConversionCopyOutput',
    'BudgetAction',
    'OpportunityDiscovery',
    'ExperimentResult',
    
    # Engines/Agents
    'SearchIntentEngine',
    'ConversionCopyAgent',
    'BudgetingAgent',
    'OpportunityDiscoveryAgent',
    'OptimizationAgent',
    'FunnelTab',
    'GROASEngine'
]
